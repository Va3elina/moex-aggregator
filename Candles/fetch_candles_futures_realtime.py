#!/usr/bin/env python3
"""
–†–µ–∞–ª—Ç–∞–π–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –§–¨–Æ–ß–ï–†–°–û–í —á–µ—Ä–µ–∑ Algopack API.

–¢–∞–π–º—Ñ—Ä–µ–π–º—ã:
- 5 –º–∏–Ω—É—Ç (–∞–≥—Ä–µ–≥–∞—Ü–∏—è –∏–∑ 1-–º–∏–Ω—É—Ç–Ω—ã—Ö)
- 60 –º–∏–Ω—É—Ç
- 24 —á–∞—Å–∞ (–¥–Ω–µ–≤–Ω—ã–µ)

–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ (–ú–°–ö):
- 5–º: –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç (XX:00:10, XX:05:10...)
- 60–º: –∫–∞–∂–¥—ã–π —á–∞—Å (XX:00:15)
- 24—á: –≤ –ø–æ–ª–Ω–æ—á—å (00:01:00)

–¢–æ—Ä–≥–æ–≤—ã–µ —á–∞—Å—ã: 07:00-24:00 –ú–°–ö, –ü–Ω-–ü—Ç (–∫—Ä–æ–º–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ MOEX)

–†–µ–∂–∏–º—ã –∑–∞–ø—É—Å–∫–∞:
- daemon (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é): —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ
- --once: –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
- --force: –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –¥–Ω—è
"""

import asyncio
import aiohttp
import pandas as pd
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple
import logging
import sys
from pathlib import Path

# === –ò–º–ø–æ—Ä—Ç –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ ===
from dotenv import load_dotenv
import os

sys.path.insert(0, str(Path(__file__).parent.parent))
load_dotenv(Path(__file__).parent.parent / ".env")

DB_URL = os.getenv("DB_URL", "postgresql+pg8000://postgres:1803@localhost:5432/moex_db")
ALGOPACK_API_KEY = os.getenv("ALGOPACK_API_KEY", "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJaVHA2Tjg1ekE4YTBFVDZ5SFBTajJ2V0ZldzNOc2xiSVR2bnVaYWlSNS1NIn0.eyJleHAiOjE3NjYzNDk1MTYsImlhdCI6MTc2Mzc1NzUxNiwiYXV0aF90aW1lIjoxNzYzNzU3NDMzLCJqdGkiOiI2ODAxMGI5MC0wMjVjLTQ0MDctYTdiNS05OGVmMGJiZjEzNWEiLCJpc3MiOiJodHRwczovL3NzbzIubW9leC5jb20vYXV0aC9yZWFsbXMvY3JhbWwiLCJhdWQiOlsiYWNjb3VudCIsImlzcyJdLCJzdWIiOiJmOjBiYTZhOGYwLWMzOGEtNDlkNi1iYTBlLTg1NmYxZmU0YmY3ZTpmYjZjNGExMy0yYTI5LTQ3OTktOWNlNi00NDIxMmQ3Yjk3ZTMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJpc3MiLCJzaWQiOiI3NmI0ZDU1NC03Zjc2LTQ3ZmUtODZhOC02YTQwN2EwMDUzNTIiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIi8qIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoib3BlbmlkIGlzc19hbGdvcGFjayBwcm9maWxlIG9mZmxpbmVfYWNjZXNzIGVtYWlsIGJhY2t3YXJkc19jb21wYXRpYmxlIiwiZW1haWxfdmVyaWZpZWQiOmZhbHNlLCJpc3NfcGVybWlzc2lvbnMiOiIxMzcsIDEzOCwgMTM5LCAxNDAsIDE2NSwgMTY2LCAxNjcsIDE2OCwgMzI5LCA0MjEiLCJuYW1lIjoi0JDQu9C10LrRgdCw0L3QtNGAINCi0L7RgNC40Y8iLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJmYjZjNGExMy0yYTI5LTQ3OTktOWNlNi00NDIxMmQ3Yjk3ZTMiLCJnaXZlbl9uYW1lIjoi0JDQu9C10LrRgdCw0L3QtNGAIiwic2Vzc2lvbl9zdGF0ZSI6Ijc2YjRkNTU0LTdmNzYtNDdmZS04NmE4LTZhNDA3YTAwNTM1MiIsImZhbWlseV9uYW1lIjoi0KLQvtGA0LjRjyJ9.HY_5Y4AXzl2oj4cVWP8UdReIzkaxV1EXO5gzOUhtdpaXslGPUUjOXSPInEAkLunsxlB5iD2YFNWNSLj_5TBk1Avkap8BglK2oeZS_S6O4Q03nsNndSSzyCftcCxs-PxZzP78FYMVTPeVmwEonvx4vnASW-U6p-f8mjfOo6fgoflcD82dmStwOEN0OQ-hRSaaa3vuBmOqp-_GHtkBDOXxRy9idVJN4yQ_8euLTlr753b6fQd7trjXjJjfJAbHEy_idCuHI1dZTFGdSZXXSBy-E18PDUMgW4KqJIc3P8Eywi9if1ki31Dw-2XIMgMLBKC27ht0g5-BRewafepXJdkqOw")

try:
    from moex_calendar import (
        get_moscow_time,
        is_trading_hours,
        is_trading_day,
        TRADING_START_HOUR,
        TRADING_END_HOUR
    )
    CONFIG_LOADED = True
except ImportError as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ –∫–æ—Ä–Ω—è: {e}")
    print("–ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏...")
    CONFIG_LOADED = False

    # Fallback –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    TRADING_START_HOUR = 7
    TRADING_END_HOUR = 24
    TRADING_DAYS = [0, 1, 2, 3, 4]


    def get_moscow_time() -> datetime:
        try:
            import pytz
            msk = pytz.timezone('Europe/Moscow')
            return datetime.now(msk).replace(tzinfo=None)
        except ImportError:
            return datetime.utcnow() + timedelta(hours=3)


    def is_trading_hours() -> Tuple[bool, str]:
        now = get_moscow_time()
        if now.weekday() not in TRADING_DAYS:
            return False, f"–í—ã—Ö–æ–¥–Ω–æ–π ({now.strftime('%A')})"
        if now.hour < TRADING_START_HOUR:
            return False, f"–î–æ –Ω–∞—á–∞–ª–∞ —Ç–æ—Ä–≥–æ–≤ ({TRADING_START_HOUR}:00 –ú–°–ö)"
        if now.hour >= TRADING_END_HOUR:
            return False, "–¢–æ—Ä–≥–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã"
        return True, "–¢–æ—Ä–≥–æ–≤–∞—è —Å–µ—Å—Å–∏—è"


    def is_trading_day(check_date=None) -> Tuple[bool, str]:
        check = check_date or get_moscow_time().date()
        if check.weekday() not in TRADING_DAYS:
            return False, "–í—ã—Ö–æ–¥–Ω–æ–π"
        return True, "–¢–æ—Ä–≥–æ–≤—ã–π –¥–µ–Ω—å"

# === ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò ===

# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å
MAX_CONCURRENT_FETCH = 20  # –î–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å–≤–µ—á–µ–π
MAX_CONCURRENT_CHECK = 5  # –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤

# –ë—É—Ñ–µ—Ä –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è —Å–≤–µ—á–∏ (—Å–µ–∫—É–Ω–¥—ã)
BUFFER_SECONDS = 10

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ (—Å–µ–∫—É–Ω–¥—ã)
GAP_CHECK_INTERVAL = 3600

# –ö—ç—à –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ (—á–∞—Å—ã)
CONTRACT_CACHE_HOURS = 6

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ª–æ–≥–æ–≤
LOG_DIR = Path(__file__).parent / "logs"
LOG_DIR.mkdir(exist_ok=True)


# ======================================================================
#                         –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
# ======================================================================

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ–∞–π–ª –∏ –∫–æ–Ω—Å–æ–ª—å"""

    detailed_fmt = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(funcName)s:%(lineno)d | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    console_fmt = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%H:%M:%S'
    )

    root = logging.getLogger()
    root.setLevel(logging.DEBUG)
    root.handlers.clear()

    # –ö–æ–Ω—Å–æ–ª—å (INFO+)
    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.INFO)
    ch.setFormatter(console_fmt)
    root.addHandler(ch)

    # –§–∞–π–ª –≤—Å–µ—Ö –ª–æ–≥–æ–≤ (DEBUG+)
    fh_all = logging.FileHandler(
        LOG_DIR / f"candles_futures_{datetime.now():%Y%m%d}.log",
        encoding='utf-8'
    )
    fh_all.setLevel(logging.DEBUG)
    fh_all.setFormatter(detailed_fmt)
    root.addHandler(fh_all)

    # –§–∞–π–ª –æ—à–∏–±–æ–∫ (WARNING+)
    fh_err = logging.FileHandler(
        LOG_DIR / f"candles_futures_errors_{datetime.now():%Y%m%d}.log",
        encoding='utf-8'
    )
    fh_err.setLevel(logging.WARNING)
    fh_err.setFormatter(detailed_fmt)
    root.addHandler(fh_err)

    return logging.getLogger(__name__)


log = setup_logging()


# ======================================================================
#                    FUTURES MANAGER (–†–û–¢–ê–¶–ò–Ø –ö–û–ù–¢–†–ê–ö–¢–û–í)
# ======================================================================

class FuturesManager:
    """
    –ù–∞–¥—ë–∂–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Ñ—å—é—á–µ—Ä—Å–æ–≤.

    –î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞:
    1. –ë—ã—Å—Ç—Ä–∞—è (14 –¥–Ω–µ–π) ‚Äî –ø–µ—Ä–≤—ã–µ 6 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    2. –ì–ª—É–±–æ–∫–∞—è (60 –¥–Ω–µ–π) ‚Äî –µ—Å–ª–∏ –±—ã—Å—Ç—Ä–∞—è –Ω–µ –ø–æ–º–æ–≥–ª–∞

    –í—ã–±–∏—Ä–∞–µ—Ç –±–ª–∏–∂–∞–π—à–∏–π –ø–æ —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö.
    """

    MONTH_CODES = {
        'F': 1, 'G': 2, 'H': 3, 'J': 4, 'K': 5, 'M': 6,
        'N': 7, 'Q': 8, 'U': 9, 'V': 10, 'X': 11, 'Z': 12
    }

    ALL_MONTHS = ['F', 'G', 'H', 'J', 'K', 'M', 'N', 'Q', 'U', 'V', 'X', 'Z']

    def __init__(self, engine, api_key: str):
        self.engine = engine
        self.api_key = api_key
        self.headers = {'Authorization': f'Bearer {api_key}'}

        self._cache = {}
        self._cache_time = None
        self._cache_ttl = timedelta(hours=CONTRACT_CACHE_HOURS)

        log.debug("FuturesManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _is_perpetual(self, sectype: str, sec_id: str) -> bool:
        """–í–µ—á–Ω—ã–π —Ñ—å—é—á–µ—Ä—Å: sec_id == sectype"""
        return sec_id == sectype

    async def _check_contract(
            self,
            session: aiohttp.ClientSession,
            secid: str,
            days: int
    ) -> Tuple[bool, int]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö —É –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞.

        Returns: (has_data, candles_count)
        """
        url = f"https://apim.moex.com/iss/engines/futures/markets/forts/boards/rfud/securities/{secid}/candles.json"

        now = get_moscow_time()
        from_date = (now - timedelta(days=days)).strftime('%Y-%m-%d')
        till_date = now.strftime('%Y-%m-%d')

        params = {'interval': 24, 'from': from_date, 'till': till_date}

        try:
            async with session.get(
                    url,
                    headers=self.headers,
                    params=params,
                    timeout=aiohttp.ClientTimeout(total=15)
            ) as resp:
                if resp.status != 200:
                    return False, 0

                data = await resp.json()
                candles = data.get('candles', {}).get('data', [])
                return len(candles) > 0, len(candles)

        except Exception as e:
            log.debug(f"[{secid}] –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False, 0

    def _generate_candidates(self, prefix: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ"""
        now = get_moscow_time()
        current_year = now.year
        current_month = now.month

        candidates = []
        year_digit = str(current_year)[-1]
        next_year_digit = str(current_year + 1)[-1]

        # 1. –¢–µ–∫—É—â–∏–π –≥–æ–¥: –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ –º–µ—Å—è—Ü–∞
        for m in self.ALL_MONTHS:
            if self.MONTH_CODES[m] >= current_month:
                candidates.append(f"{prefix}{m}{year_digit}")

        # 2. –°–ª–µ–¥—É—é—â–∏–π –≥–æ–¥: –≤—Å–µ –º–µ—Å—è—Ü—ã
        for m in self.ALL_MONTHS:
            candidates.append(f"{prefix}{m}{next_year_digit}")

        # 3. –ü—Ä–æ—à–µ–¥—à–∏–µ –º–µ—Å—è—Ü—ã —Ç–µ–∫—É—â–µ–≥–æ –≥–æ–¥–∞ (–º–æ–≥—É—Ç –µ—â—ë —Ç–æ—Ä–≥–æ–≤–∞—Ç—å—Å—è)
        for m in self.ALL_MONTHS:
            ticker = f"{prefix}{m}{year_digit}"
            if ticker not in candidates:
                candidates.append(ticker)

        return candidates

    def _get_expiry_order(self, secid: str) -> Tuple[int, int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫ —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏"""
        if len(secid) < 2:
            return (9999, 99)

        year_digit = secid[-1]
        month_letter = secid[-2]

        if not year_digit.isdigit() or month_letter not in self.MONTH_CODES:
            return (9999, 99)

        current_year = get_moscow_time().year
        year = (current_year // 10) * 10 + int(year_digit)

        if year < current_year - 1:
            year += 10

        month = self.MONTH_CODES[month_letter]
        return (year, month)

    async def _find_active_contract(
            self,
            session: aiohttp.ClientSession,
            sectype: str,
            prefix: str,
            name: str
    ) -> Optional[tuple]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –∞–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç—Ä–∞–∫—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π.
        """
        candidates = self._generate_candidates(prefix)

        # === –≠–¢–ê–ü 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (14 –¥–Ω–µ–π, –ø–µ—Ä–≤—ã–µ 6) ===
        log.debug(f"[{sectype}] –≠—Ç–∞–ø 1: –±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞...")

        for secid in candidates[:6]:
            has_data, count = await self._check_contract(session, secid, days=14)

            if has_data:
                base_secid = secid[:-1]
                log.debug(f"[{sectype}] ‚úì {secid} (–≠—Ç–∞–ø 1, —Å–≤–µ—á–µ–π: {count})")
                return (secid, base_secid, name, sectype)

        # === –≠–¢–ê–ü 2: –ì–ª—É–±–æ–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (60 –¥–Ω–µ–π, –ø–µ—Ä–≤—ã–µ 10) ===
        log.debug(f"[{sectype}] –≠—Ç–∞–ø 2: –≥–ª—É–±–æ–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞...")

        found = []

        for secid in candidates[:10]:
            has_data, count = await self._check_contract(session, secid, days=60)

            if has_data:
                found.append({
                    'secid': secid,
                    'base_secid': secid[:-1],
                    'count': count,
                    'order': self._get_expiry_order(secid)
                })

        if not found:
            log.warning(f"[{sectype}] ‚úó –ö–æ–Ω—Ç—Ä–∞–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return None

        # –í—ã–±–∏—Ä–∞–µ–º –±–ª–∏–∂–∞–π—à–∏–π –ø–æ —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏
        found.sort(key=lambda x: x['order'])
        best = found[0]

        log.debug(f"[{sectype}] ‚úì {best['secid']} (–≠—Ç–∞–ø 2, –±–ª–∏–∂–∞–π—à–∏–π)")
        return (best['secid'], best['base_secid'], name, sectype)

    def load_instruments(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏–∑ –ë–î"""
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –ë–î...")

        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(text("""
                                      SELECT name, sectype, sec_id
                                      FROM instruments
                                      WHERE type = 'futures'
                                      """), conn)
            log.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ instruments: {e}")
            return {}

        instruments = {}

        for _, row in df.iterrows():
            sectype = row['sectype']
            sec_id = row['sec_id']
            name = row['name']

            if not sec_id or not sectype:
                continue

            if sectype not in instruments:
                instruments[sectype] = {
                    'name': name,
                    'prefix': None,
                    'perpetual': None
                }

            if self._is_perpetual(sectype, sec_id):
                instruments[sectype]['perpetual'] = sec_id
            else:
                instruments[sectype]['prefix'] = sec_id[:-1]

        log.debug(f"–°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–æ {len(instruments)} –±–∞–∑–æ–≤—ã—Ö –∞–∫—Ç–∏–≤–æ–≤")
        return instruments

    async def get_active_contracts(self, session: aiohttp.ClientSession) -> List[tuple]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤"""
        now = datetime.now()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if self._cache_time and (now - self._cache_time) < self._cache_ttl and self._cache:
            log.debug(f"–ö—ç—à –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤: {len(self._cache)} —à—Ç")
            return list(self._cache.values())

        log.info("üîç –ü–æ–∏—Å–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤...")

        instruments = self.load_instruments()
        contracts = []

        # === –í–µ—á–Ω—ã–µ —Ñ—å—é—á–µ—Ä—Å—ã ===
        perpetual_count = 0
        for sectype, data in instruments.items():
            if data.get('perpetual'):
                sec_id = data['perpetual']
                contracts.append((sec_id, sec_id, data['name'], sectype))
                perpetual_count += 1
                log.debug(f"  ‚úì {sec_id} (–≤–µ—á–Ω—ã–π)")

        log.info(f"  –í–µ—á–Ω—ã—Ö: {perpetual_count}")

        # === –û–±—ã—á–Ω—ã–µ —Ñ—å—é—á–µ—Ä—Å—ã ===
        regular = [(st, d) for st, d in instruments.items()
                   if d.get('prefix') and not d.get('perpetual')]

        log.info(f"  –ü—Ä–æ–≤–µ—Ä–∫–∞ {len(regular)} –æ–±—ã—á–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤...")

        semaphore = asyncio.Semaphore(MAX_CONCURRENT_CHECK)

        async def find(sectype, data):
            async with semaphore:
                return await self._find_active_contract(
                    session, sectype, data['prefix'], data['name']
                )

        results = await asyncio.gather(
            *[find(st, d) for st, d in regular],
            return_exceptions=True
        )

        found = 0
        not_found = 0

        for r in results:
            if isinstance(r, tuple) and r:
                contracts.append(r)
                found += 1
            elif isinstance(r, Exception):
                log.error(f"–û—à–∏–±–∫–∞: {r}")
                not_found += 1
            else:
                not_found += 1

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
        self._cache = {c[0]: c for c in contracts}
        self._cache_time = now

        log.info(f"‚úì –ù–∞–π–¥–µ–Ω–æ: {found + perpetual_count}, –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {not_found}")
        return contracts

    def invalidate_cache(self):
        """–°–±—Ä–æ—Å –∫—ç—à–∞"""
        self._cache = {}
        self._cache_time = None
        log.info("–ö—ç—à –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ —Å–±—Ä–æ—à–µ–Ω")


# ======================================================================
#                    ALGOPACK FETCHER
# ======================================================================

class AlgopackFetcher:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ —Å–≤–µ—á–µ–π —á–µ—Ä–µ–∑ Algopack API"""

    BASE_URL = "https://apim.moex.com/iss/engines/futures/markets/forts/boards/rfud/securities"

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.headers = {'Authorization': f'Bearer {api_key}'}

        self.stats = {
            'requests': 0,
            'success': 0,
            'errors': 0,
            'empty': 0
        }

    def get_stats(self) -> dict:
        return self.stats.copy()

    def reset_stats(self):
        for k in self.stats:
            self.stats[k] = 0

    async def fetch_candles(
            self,
            session: aiohttp.ClientSession,
            secid: str,
            interval: int,
            from_date: str,
            till_date: str
    ) -> Optional[pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–≤–µ—á–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""

        url = f"{self.BASE_URL}/{secid}/candles.json"
        params = {
            'interval': interval,
            'from': from_date,
            'till': till_date
        }

        all_candles = []
        columns = None
        start = 0

        while True:
            params['start'] = start
            self.stats['requests'] += 1

            try:
                async with session.get(
                        url,
                        headers=self.headers,
                        params=params,
                        timeout=aiohttp.ClientTimeout(total=30)
                ) as resp:

                    if resp.status == 401:
                        log.error(f"[{secid}] –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (401)")
                        self.stats['errors'] += 1
                        return None

                    if resp.status == 429:
                        log.warning(f"[{secid}] –õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (429), –∂–¥—ë–º 60 —Å–µ–∫...")
                        await asyncio.sleep(60)
                        continue

                    if resp.status != 200:
                        log.debug(f"[{secid}] HTTP {resp.status}")
                        self.stats['errors'] += 1
                        return None

                    try:
                        data = await resp.json()
                    except:
                        log.warning(f"[{secid}] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON")
                        self.stats['errors'] += 1
                        return None

                    if "candles" not in data or not data["candles"].get("data"):
                        if start == 0:
                            self.stats['empty'] += 1
                        break

                    candles = data["candles"]["data"]
                    columns = data["candles"]["columns"]
                    all_candles.extend(candles)

                    if len(candles) < 500:
                        break

                    start += len(candles)
                    await asyncio.sleep(0.05)

            except asyncio.TimeoutError:
                log.error(f"[{secid}] –¢–∞–π–º–∞—É—Ç")
                self.stats['errors'] += 1
                return None
            except Exception as e:
                log.error(f"[{secid}] –û—à–∏–±–∫–∞: {e}")
                self.stats['errors'] += 1
                return None

        if not all_candles or not columns:
            return None

        self.stats['success'] += 1

        df = pd.DataFrame(all_candles, columns=columns)
        df["begin_time"] = pd.to_datetime(df["begin"]).dt.tz_localize(None)
        df["end_time"] = pd.to_datetime(df["end"]).dt.tz_localize(None)
        df["interval"] = interval
        df["secid"] = secid
        df["type"] = "futures"
        df = df.drop(["begin", "end"], axis=1)

        return df


# ======================================================================
#                    –ê–ì–†–ï–ì–ê–¶–ò–Ø 1–ú ‚Üí 5–ú
# ======================================================================

def aggregate_to_5min(df_1min: pd.DataFrame) -> pd.DataFrame:
    """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç 1-–º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏ –≤ 5-–º–∏–Ω—É—Ç–Ω—ã–µ"""

    if df_1min.empty:
        return pd.DataFrame()

    df = df_1min.copy().sort_values('begin_time')
    df['interval_5min'] = df['begin_time'].dt.floor('5min')

    secid = df['secid'].iloc[0]
    sec_id = df['sec_id'].iloc[0] if 'sec_id' in df.columns else None

    agg = {
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum',
        'value': 'sum',
    }

    df_5min = df.groupby('interval_5min').agg(agg).reset_index()
    df_5min.rename(columns={'interval_5min': 'begin_time'}, inplace=True)
    df_5min['end_time'] = df_5min['begin_time'] + pd.Timedelta(minutes=5)
    df_5min['interval'] = 5
    df_5min['secid'] = secid
    df_5min['sec_id'] = sec_id
    df_5min['type'] = 'futures'

    return df_5min


# ======================================================================
#                    CANDLES UPDATER
# ======================================================================

class CandlesUpdater:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π"""

    def __init__(self, db_url: str, api_key: str):
        log.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CandlesUpdater...")

        try:
            self.engine = create_engine(db_url)
            with self.engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            log.info("‚úì –ë–î –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
        except Exception as e:
            log.critical(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            raise

        self.api_key = api_key
        self.fetcher = AlgopackFetcher(api_key)
        self.futures_manager = FuturesManager(self.engine, api_key)

        self.last_5min_update = None
        self.last_60min_update = None
        self.last_daily_update = None
        self.last_gap_check = None

        self.session_stats = {
            'start_time': datetime.now(),
            'cycles': 0,
            'candles_saved': {5: 0, 60: 0, 24: 0},
            'errors': 0
        }

        log.info("‚úì CandlesUpdater –≥–æ—Ç–æ–≤")

    def get_last_candle_time(self, secid: str, interval: int) -> Optional[datetime]:
        """–í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–∏ –≤ –ë–î"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("""
                                           SELECT MAX(begin_time)
                                           FROM candles
                                           WHERE secid = :secid
                                             AND "interval" = :interval
                                           """), {'secid': secid, 'interval': interval})
                row = result.fetchone()
                return row[0] if row and row[0] else None
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–∏: {e}")
            return None

    def save_candles(self, df: pd.DataFrame) -> Tuple[int, int]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–≤–µ—á–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–ø–æ–ø—ã—Ç–æ–∫, –≤—Å—Ç–∞–≤–ª–µ–Ω–æ)"""

        if df.empty:
            return 0, 0

        for col in ['value', 'volume', 'open', 'close', 'high', 'low']:
            if col in df.columns:
                df[col] = df[col].fillna(0)

        try:
            raw_conn = self.engine.raw_connection()
            cursor = raw_conn.cursor()

            columns = [
                'secid', 'begin_time', 'interval', 'type', 'end_time',
                'open', 'close', 'high', 'low', 'value', 'volume', 'sec_id'
            ]

            for col in columns:
                if col not in df.columns:
                    df[col] = None

            records = [tuple(x) for x in df[columns].to_numpy()]

            insert_query = """
                           INSERT INTO candles (secid, begin_time, interval, type, end_time,
                                                open, close, high, low, value, volume, sec_id)
                           VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \
                                   %s) ON CONFLICT (secid, begin_time, interval, type) DO NOTHING
                           """

            inserted = 0
            for record in records:
                cursor.execute(insert_query, record)
                inserted += cursor.rowcount

            raw_conn.commit()
            cursor.close()
            raw_conn.close()

            return len(records), inserted

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            self.session_stats['errors'] += 1
            return 0, 0

    async def update_5min(
            self,
            session: aiohttp.ClientSession,
            contracts: List[tuple]
    ) -> Tuple[int, int]:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç 5-–º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏"""

        now = get_moscow_time()
        till_date = now.strftime('%Y-%m-%d')
        total_attempted = 0
        total_inserted = 0

        semaphore = asyncio.Semaphore(MAX_CONCURRENT_FETCH)

        async def process(secid, sec_id, name, sectype):
            async with semaphore:
                last_time = self.get_last_candle_time(secid, 5)

                if last_time:
                    from_date = last_time.strftime('%Y-%m-%d')
                else:
                    from_date = (now - timedelta(days=7)).strftime('%Y-%m-%d')

                df_1min = await self.fetcher.fetch_candles(
                    session, secid, 1, from_date, till_date
                )

                if df_1min is None or df_1min.empty:
                    return 0, 0

                df_1min['sec_id'] = sec_id
                df_5min = aggregate_to_5min(df_1min)

                if not df_5min.empty and last_time:
                    df_5min = df_5min[df_5min['begin_time'] > last_time]

                if df_5min.empty:
                    return 0, 0

                return self.save_candles(df_5min)

        tasks = [process(c[0], c[1], c[2], c[3]) for c in contracts]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        for r in results:
            if isinstance(r, tuple):
                total_attempted += r[0]
                total_inserted += r[1]

        self.session_stats['candles_saved'][5] += total_inserted
        return total_attempted, total_inserted

    async def update_60min(
            self,
            session: aiohttp.ClientSession,
            contracts: List[tuple]
    ) -> Tuple[int, int]:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —á–∞—Å–æ–≤—ã–µ —Å–≤–µ—á–∏"""

        now = get_moscow_time()
        till_date = now.strftime('%Y-%m-%d')
        total_attempted = 0
        total_inserted = 0

        semaphore = asyncio.Semaphore(MAX_CONCURRENT_FETCH)

        async def process(secid, sec_id, name, sectype):
            async with semaphore:
                last_time = self.get_last_candle_time(secid, 60)

                if last_time:
                    from_date = last_time.strftime('%Y-%m-%d')
                else:
                    from_date = (now - timedelta(days=30)).strftime('%Y-%m-%d')

                df = await self.fetcher.fetch_candles(
                    session, secid, 60, from_date, till_date
                )

                if df is None or df.empty:
                    return 0, 0

                df['sec_id'] = sec_id

                if last_time:
                    df = df[df['begin_time'] > last_time]

                if df.empty:
                    return 0, 0

                return self.save_candles(df)

        tasks = [process(c[0], c[1], c[2], c[3]) for c in contracts]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        for r in results:
            if isinstance(r, tuple):
                total_attempted += r[0]
                total_inserted += r[1]

        self.session_stats['candles_saved'][60] += total_inserted
        return total_attempted, total_inserted

    async def update_daily(
            self,
            session: aiohttp.ClientSession,
            contracts: List[tuple]
    ) -> Tuple[int, int]:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–Ω–µ–≤–Ω—ã–µ —Å–≤–µ—á–∏"""

        now = get_moscow_time()
        till_date = now.strftime('%Y-%m-%d')
        total_attempted = 0
        total_inserted = 0

        semaphore = asyncio.Semaphore(MAX_CONCURRENT_FETCH)

        async def process(secid, sec_id, name, sectype):
            async with semaphore:
                last_time = self.get_last_candle_time(secid, 24)

                if last_time:
                    from_date = last_time.strftime('%Y-%m-%d')
                else:
                    from_date = (now - timedelta(days=365)).strftime('%Y-%m-%d')

                df = await self.fetcher.fetch_candles(
                    session, secid, 24, from_date, till_date
                )

                if df is None or df.empty:
                    return 0, 0

                df['sec_id'] = sec_id

                if last_time:
                    df = df[df['begin_time'] > last_time]

                if df.empty:
                    return 0, 0

                return self.save_candles(df)

        tasks = [process(c[0], c[1], c[2], c[3]) for c in contracts]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        for r in results:
            if isinstance(r, tuple):
                total_attempted += r[0]
                total_inserted += r[1]

        self.session_stats['candles_saved'][24] += total_inserted
        return total_attempted, total_inserted

    async def check_data_gaps(self, contracts: List[tuple]):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö"""
        log.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤...")

        now = get_moscow_time()
        gaps = []

        for secid, _, name, _ in contracts[:20]:
            last = self.get_last_candle_time(secid, 5)

            if last is None:
                gaps.append(f"{secid}: –ù–ï–¢ –î–ê–ù–ù–´–•")
            elif (now - last) > timedelta(hours=2):
                gap = now - last
                gaps.append(f"{secid}: {gap}")

        if gaps:
            log.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∏ ({len(gaps)}):")
            for g in gaps[:5]:
                log.warning(f"  {g}")
        else:
            log.info("‚úì –ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ—Ç")

    def _get_5min_slot(self) -> datetime:
        now = get_moscow_time()
        return now.replace(second=0, microsecond=0, minute=(now.minute // 5) * 5)

    def _get_hour_slot(self) -> datetime:
        now = get_moscow_time()
        return now.replace(second=0, microsecond=0, minute=0)

    def _get_day_slot(self) -> datetime:
        now = get_moscow_time()
        return now.replace(second=0, microsecond=0, minute=0, hour=0)

    def print_stats(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏"""
        uptime = datetime.now() - self.session_stats['start_time']
        api = self.fetcher.get_stats()

        log.info("=" * 50)
        log.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        log.info(f"  –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {uptime}")
        log.info(f"  –¶–∏–∫–ª–æ–≤: {self.session_stats['cycles']}")
        log.info(f"  –°–≤–µ—á–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ:")
        log.info(f"    5–º: {self.session_stats['candles_saved'][5]}")
        log.info(f"    60–º: {self.session_stats['candles_saved'][60]}")
        log.info(f"    24—á: {self.session_stats['candles_saved'][24]}")
        log.info(f"  API: {api['requests']} –∑–∞–ø—Ä–æ—Å–æ–≤, {api['success']} —É—Å–ø–µ—à–Ω—ã—Ö")
        log.info("=" * 50)

    async def run_once(self, session: aiohttp.ClientSession) -> Dict[int, int]:
        """
        –û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {interval: inserted_count}
        """
        results = {}

        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã
        contracts = await self.futures_manager.get_active_contracts(session)
        log.info(f"üìã –ö–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤: {len(contracts)}")

        # 5-–º–∏–Ω—É—Ç–∫–∏
        log.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ 5–º...")
        att, ins = await self.update_5min(session, contracts)
        results[5] = ins
        log.info(f"  ‚úì 5–º: +{ins} –Ω–æ–≤—ã—Ö")

        # –ß–∞—Å–æ–≤—ã–µ
        log.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ 60–º...")
        att, ins = await self.update_60min(session, contracts)
        results[60] = ins
        log.info(f"  ‚úì 60–º: +{ins} –Ω–æ–≤—ã—Ö")

        # –î–Ω–µ–≤–Ω—ã–µ
        log.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ 24—á...")
        att, ins = await self.update_daily(session, contracts)
        results[24] = ins
        log.info(f"  ‚úì 24—á: +{ins} –Ω–æ–≤—ã—Ö")

        return results

    async def run_forever(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª"""

        log.info("=" * 60)
        log.info("üöÄ –ó–ê–ü–£–°–ö –†–ï–ê–õ–¢–ê–ô–ú –û–ë–ù–û–í–õ–ï–ù–ò–Ø –°–í–ï–ß–ï–ô")
        log.info(f"  API: Algopack")
        log.info(f"  –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å: {MAX_CONCURRENT_FETCH}")
        log.info(f"  –¢–æ—Ä–≥–æ–≤—ã–µ —á–∞—Å—ã: {TRADING_START_HOUR}:00 - {TRADING_END_HOUR}:00 –ú–°–ö")
        log.info(f"  –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ:")
        log.info(f"    5–º: XX:00:10, XX:05:10...")
        log.info(f"    60–º: XX:00:15")
        log.info(f"    24—á: 00:01:00")
        log.info(f"  –õ–æ–≥–∏: {LOG_DIR.absolute()}")
        log.info("=" * 60)

        connector = aiohttp.TCPConnector(limit=MAX_CONCURRENT_FETCH)
        timeout = aiohttp.ClientTimeout(total=120)

        retry_count = 0
        max_retries = 5

        while True:
            try:
                async with aiohttp.ClientSession(
                        connector=connector,
                        timeout=timeout
                ) as session:

                    # === –ù–∞—á–∞–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è ===
                    contracts = await self.futures_manager.get_active_contracts(session)
                    log.info(f"üìã –ö–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤: {len(contracts)}")

                    log.info("üîÑ –ù–∞—á–∞–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è...")

                    att, ins = await self.update_5min(session, contracts)
                    log.info(f"  ‚úì 5–º: +{ins} –Ω–æ–≤—ã—Ö")

                    att, ins = await self.update_60min(session, contracts)
                    log.info(f"  ‚úì 60–º: +{ins} –Ω–æ–≤—ã—Ö")

                    att, ins = await self.update_daily(session, contracts)
                    log.info(f"  ‚úì 24—á: +{ins} –Ω–æ–≤—ã—Ö")

                    self.last_5min_update = self._get_5min_slot()
                    self.last_60min_update = self._get_hour_slot()
                    self.last_daily_update = self._get_day_slot()
                    self.last_gap_check = datetime.now()

                    log.info("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                    log.info("=" * 60)

                    retry_count = 0

                    # === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ===
                    while True:
                        now = get_moscow_time()

                        is_trading, reason = is_trading_hours()
                        if not is_trading:
                            log.debug(f"–í–Ω–µ —Ç–æ—Ä–≥–æ–≤: {reason}")
                            await asyncio.sleep(60)
                            continue

                        slot_5min = self._get_5min_slot()
                        slot_hour = self._get_hour_slot()
                        slot_day = self._get_day_slot()

                        # === 5-–º–∏–Ω—É—Ç–∫–∏ ===
                        if slot_5min != self.last_5min_update and now.second >= BUFFER_SECONDS:
                            contracts = await self.futures_manager.get_active_contracts(session)

                            log.info(f"üìä [{now:%H:%M:%S} –ú–°–ö] 5-–º–∏–Ω—É—Ç–∫–∏...")
                            att, ins = await self.update_5min(session, contracts)
                            self.last_5min_update = slot_5min
                            self.session_stats['cycles'] += 1

                            log.info(f"  ‚úì +{ins} –Ω–æ–≤—ã—Ö")

                        # === –ß–∞—Å–æ–≤—ã–µ ===
                        if slot_hour != self.last_60min_update and now.minute == 0 and now.second >= 15:
                            contracts = await self.futures_manager.get_active_contracts(session)

                            log.info(f"üìä [{now:%H:%M:%S} –ú–°–ö] –ß–∞—Å–æ–≤—ã–µ...")
                            att, ins = await self.update_60min(session, contracts)
                            self.last_60min_update = slot_hour

                            log.info(f"  ‚úì +{ins} –Ω–æ–≤—ã—Ö")

                        # === –î–Ω–µ–≤–Ω—ã–µ ===
                        if slot_day != self.last_daily_update and now.hour == 0 and now.minute >= 1:
                            contracts = await self.futures_manager.get_active_contracts(session)

                            log.info(f"üìä [{now:%H:%M:%S} –ú–°–ö] –î–Ω–µ–≤–Ω—ã–µ...")
                            att, ins = await self.update_daily(session, contracts)
                            self.last_daily_update = slot_day

                            log.info(f"  ‚úì +{ins} –Ω–æ–≤—ã—Ö")
                            self.print_stats()

                        # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ ===
                        if (datetime.now() - self.last_gap_check).seconds >= GAP_CHECK_INTERVAL:
                            contracts = await self.futures_manager.get_active_contracts(session)
                            await self.check_data_gaps(contracts)
                            self.last_gap_check = datetime.now()

                        await asyncio.sleep(1)

            except aiohttp.ClientError as e:
                retry_count += 1
                log.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
                log.warning(f"  –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ {retry_count}/{max_retries}...")

                if retry_count >= max_retries:
                    log.critical("‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫!")
                    self.print_stats()
                    raise

                await asyncio.sleep(30 * retry_count)

            except KeyboardInterrupt:
                log.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞...")
                self.print_stats()
                break

            except Exception as e:
                log.critical(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
                self.session_stats['errors'] += 1
                await asyncio.sleep(60)


# ======================================================================
#                         ENTRY POINT
# ======================================================================

async def main():
    import argparse

    parser = argparse.ArgumentParser(description='–ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–µ—á–µ–π —Ñ—å—é—á–µ—Ä—Å–æ–≤ —á–µ—Ä–µ–∑ Algopack')
    parser.add_argument('--once', action='store_true', help='–û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ')
    parser.add_argument('--force', action='store_true', help='–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –¥–Ω—è')
    args = parser.parse_args()

    log.info("=" * 60)
    log.info("–ó–ê–ü–£–°–ö –°–ö–†–ò–ü–¢–ê –û–ë–ù–û–í–õ–ï–ù–ò–Ø –°–í–ï–ß–ï–ô –§–¨–Æ–ß–ï–†–°–û–í")
    log.info(f"–í—Ä–µ–º—è: {datetime.now()}")
    log.info(f"–ú–°–ö: {get_moscow_time()}")
    log.info(f"–†–µ–∂–∏–º: {'–æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω—ã–π' if args.once else 'daemon'}")
    if CONFIG_LOADED:
        log.info("‚úì –ö–æ–Ω—Ñ–∏–≥ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏")
    else:
        log.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
    log.info("=" * 60)

    # === –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞ ===
    if not ALGOPACK_API_KEY or ALGOPACK_API_KEY == "":
        log.critical("‚ùå –£–∫–∞–∂–∏ API –∫–ª—é—á –≤ config.py!")
        return

    # === –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –¥–Ω—è –≤ —Ä–µ–∂–∏–º–µ --once ===
    if args.once and not args.force:
        is_trading, reason = is_trading_day()
        if not is_trading:
            log.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫: {reason}")
            log.info("  (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)")
            return

    try:
        updater = CandlesUpdater(DB_URL, ALGOPACK_API_KEY)

        if args.once:
            # –û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            connector = aiohttp.TCPConnector(limit=MAX_CONCURRENT_FETCH)
            timeout = aiohttp.ClientTimeout(total=120)
            async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                results = await updater.run_once(session)
                log.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ: 5–º=+{results.get(5, 0)}, 60–º=+{results.get(60, 0)}, 24—á=+{results.get(24, 0)}")
        else:
            # –†–µ–∂–∏–º daemon
            await updater.run_forever()

    except Exception as e:
        log.critical(f"‚ùå –§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        log.info("–ó–∞–≤–µ—Ä—à–µ–Ω–æ")
    except Exception as e:
        log.critical(f"–û—à–∏–±–∫–∞: {e}")
        sys.exit(1)